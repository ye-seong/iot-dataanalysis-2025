{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e83a63",
   "metadata": {},
   "source": [
    "## YOLO\n",
    "\n",
    "### PyTorch 기반 물체인식 모델\n",
    "- CNN, rCNN(Regions with CNN)\n",
    "- https://github.com/ultralytics/ultralytics 참조\n",
    "\n",
    "#### YOLOv5 이상 설치\n",
    "```shell\n",
    "> pip install ultralytics\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01333097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.21.0+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.8 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 317.4/974.8 kB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 942.1/974.8 kB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 974.8/974.8 kB 12.4 MB/s eta 0:00:00\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 122.9/162.0 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.0/162.0 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, pyyaml, opencv-python, ultralytics-thop, ultralytics\n",
      "Successfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 pyyaml-6.0.2 ultralytics-8.3.109 ultralytics-thop-2.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# YOLO 설치\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1695b9",
   "metadata": {},
   "source": [
    "#### 콘솔에서 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a5be82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109 🚀 Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Source\\iot-dataanalysis-2025\\day08\\bus.jpg: 640x480 4 persons, 1 bus, 59.6ms\n",
      "Speed: 2.2ms preprocess, 59.6ms inference, 78.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Source\\iot-dataanalysis-2025\\runs\\detect\\predict2\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# 콘솔에서 예측\n",
    "## yolo11n.pt - pretrained YOLO model\n",
    "## 자동으로 yolo11n.pt 다운로드\n",
    "## 웹 URL에 있는 이미지도 예측이 가능\n",
    "!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4537ca",
   "metadata": {},
   "source": [
    "#### 파이썬으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de05a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 모듈 로드\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838ff886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 클래스가 들어오는 모델의 버전에 따라 알아서 YOLO 예측모델 객체 생성\n",
    "model = YOLO('./yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5fa30",
   "metadata": {},
   "source": [
    "##### coco8.yaml\n",
    "- https://github.com/ultralytics/assets/releases/download/v0.0.0/coco8.zip\n",
    "- 위 내용대로 훈련을 시킨 결과 -> yolo11n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81611806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=./yolo11n.pt, data=./coco8.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\n",
      "WARNING:tensorflow:From c:\\Source\\iot-dataanalysis-2025\\mlvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Source\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100     0.672G      1.098       2.75      1.479         21        640: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.567       0.85      0.878      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100     0.697G      1.163      2.778      1.474         36        640: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557       0.85      0.887      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100     0.703G      1.089      2.497      1.216         20        640: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.559       0.85       0.85      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100     0.707G      1.164      2.793      1.485         21        640: 100%|██████████| 1/1 [00:00<00:00,  9.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.543       0.85      0.858      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100     0.707G       1.21      2.467      1.617         19        640: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.548       0.85      0.858      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100     0.734G     0.8327      1.918      1.148         22        640: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.859      0.858      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100     0.734G      1.407      2.753      1.768         20        640: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.534      0.864      0.859      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100     0.734G      1.241      3.857      1.692         20        640: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.557      0.867      0.863      0.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100     0.734G     0.9127      2.976      1.275         20        640: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.544      0.867      0.897      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100     0.734G       1.08      2.198      1.296         25        640: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.533      0.867      0.895      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100     0.734G      1.173      2.263      1.557         31        640: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.644      0.944      0.912       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100     0.734G      1.014      2.356      1.396         31        640: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.649      0.944      0.911      0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100     0.748G      1.366      3.254      1.807         24        640: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.912      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100     0.762G     0.8433      2.457      1.262         15        640: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.63       0.95      0.913      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100     0.777G      1.271       3.04      1.525         38        640: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.633      0.783       0.91      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100     0.777G      1.211       2.04      1.509         49        640: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.634      0.783       0.91       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100     0.777G     0.8203      1.549      1.184         25        640: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.641      0.783      0.911      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100     0.781G     0.6249      1.342     0.9999         16        640: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.641      0.783      0.911      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100     0.799G     0.7282      1.613      1.054         34        640: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.823       0.65      0.872       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100     0.809G      1.177      1.758       1.35         25        640: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.823       0.65      0.872       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100     0.816G     0.7776      1.808      1.186         26        640: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100     0.838G      1.074        1.7      1.246         52        640: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.789       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100     0.854G     0.9644      1.743      1.406         22        640: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100     0.859G     0.9311      1.658      1.233         34        640: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100     0.869G     0.6523      2.014      1.068         11        640: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100     0.869G     0.8513      1.312      1.179         35        640: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.778       0.65      0.856      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100     0.869G     0.9637       1.47      1.404         24        640: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.761       0.65      0.855      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100     0.869G      0.965      1.211      1.248         35        640: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.761       0.65      0.855      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100     0.869G     0.9284      1.656      1.281         28        640: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.763       0.65      0.855      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100     0.869G      1.035      1.272      1.322         29        640: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.763       0.65      0.855      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100     0.869G      1.009      1.692      1.347         25        640: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.745       0.65      0.855      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100     0.869G     0.6691      1.512      1.309         20        640: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.745       0.65      0.855      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100     0.869G      1.045      1.949      1.348         31        640: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.771       0.65      0.861      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100     0.869G      1.075      1.947      1.457         32        640: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.771       0.65      0.861      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100     0.869G     0.9153      1.245      1.311         23        640: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.783       0.65      0.852      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100     0.869G      1.023       1.47      1.386         34        640: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.783       0.65      0.852      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100     0.869G     0.9758      1.044      1.337         34        640: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795       0.65      0.849      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100     0.869G     0.5493     0.8292     0.9508         29        640: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.795       0.65      0.849      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100     0.869G     0.7212     0.7923      1.174         25        640: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.716       0.65      0.851      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100     0.869G     0.7664      1.003      1.164         19        640: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.716       0.65      0.851      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100     0.869G     0.7671      1.106      1.122         29        640: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.699       0.65       0.85      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100     0.869G      0.896       1.09      1.177         34        640: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.699       0.65       0.85      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100     0.869G      1.001     0.9861      1.479         20        640: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.776       0.65      0.848      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100     0.869G     0.6848     0.9406      1.084         23        640: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.776       0.65      0.848      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100     0.869G     0.6584      1.435       1.09         40        640: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.798       0.65      0.847      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100     0.869G     0.8697      1.017      1.258         23        640: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.798       0.65      0.847      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100     0.869G     0.8764     0.7681      1.263         14        640: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.631      0.848      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100     0.869G     0.7879      1.029      1.148         31        640: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.819      0.631      0.848      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100     0.869G     0.9999      1.108      1.374         17        640: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.802      0.649      0.766      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100     0.869G     0.6589     0.8777      1.103         31        640: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.802      0.649      0.766      0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100     0.869G     0.7199     0.9254      1.211         35        640: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100     0.869G     0.8262      1.654       1.19         55        640: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100     0.869G     0.6383      1.049       1.08         14        640: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.734      0.567      0.673      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100     0.869G     0.7169     0.9855      1.103         46        640: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100     0.869G     0.6532      1.136      1.145         30        640: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100     0.869G     0.6833      0.849      1.217         22        640: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.791      0.483      0.683      0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100     0.869G     0.7164     0.7322      1.212         28        640: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100     0.869G     0.7792      1.026      1.192         11        640: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100     0.869G     0.7671     0.7373      1.254         16        640: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.794      0.483      0.683      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100     0.869G     0.7434      1.025      1.287         30        640: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100     0.869G     0.6051      0.688      1.063         26        640: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100     0.869G     0.7546     0.9266      1.297         20        640: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.543      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100     0.869G     0.6662     0.8457      1.163         16        640: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100     0.869G     0.7963     0.7768      1.086         26        640: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100     0.869G     0.6187      0.695      1.042         37        640: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.472      0.532      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100     0.869G     0.9413      1.951      1.333         51        640: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100     0.869G     0.7584     0.9315      1.182         37        640: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100     0.869G     0.6322     0.7745      1.027         31        640: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.849      0.479      0.523       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100     0.869G     0.7433     0.7106       1.29         12        640: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100     0.869G      1.022      1.079      1.452          9        640: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100     0.869G     0.6662      0.703      1.152         23        640: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.845       0.48      0.524      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100     0.869G     0.6165     0.9729      1.152         21        640: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100     0.869G     0.5635     0.5976      1.116         15        640: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100     0.869G      1.061       1.89      1.486         28        640: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.829      0.481       0.53       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100     0.869G     0.9339     0.8899      1.234         60        640: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100     0.869G     0.9155     0.8915      1.335         14        640: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100     0.869G     0.6779     0.6292      1.043         37        640: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.862      0.476      0.526      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100     0.869G     0.6606      1.006      1.126         45        640: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100     0.869G     0.8996      1.456      1.344         16        640: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100     0.869G      0.621     0.6226       1.12         21        640: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.855      0.459      0.523      0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100     0.869G     0.7918     0.7814      1.107         42        640: 100%|██████████| 1/1 [00:00<00:00,  8.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100     0.869G     0.4436     0.4465     0.9404         32        640: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100     0.869G     0.6752     0.7486      1.039         31        640: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.856      0.456      0.525      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100     0.869G     0.8206      1.379      1.272         30        640: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100     0.869G     0.6159     0.7253      1.174         26        640: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100     0.869G     0.6397     0.8651      1.157         24        640: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100     0.869G     0.5913     0.6655      1.095         31        640: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.851      0.457      0.527      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100     0.869G     0.7254     0.9907      1.119         47        640: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100     0.869G     0.6493     0.7954      1.159         26        640: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100     0.869G     0.8045     0.6919      1.105         31        640: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100     0.869G      0.571     0.5492       1.06         13        640: 100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.809      0.444      0.511      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100     0.869G     0.4512     0.4808     0.8512         13        640: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100     0.869G     0.4633     0.4968     0.9587         13        640: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100     0.869G      0.609     0.6229      1.094         13        640: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100     0.869G     0.5564     0.6846      1.062         13        640: 100%|██████████| 1/1 [00:00<00:00, 12.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.86      0.456      0.521      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100     0.869G     0.8399     0.7876      1.226         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100     0.869G      0.521      0.455     0.8951         13        640: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100     0.869G     0.5424     0.6244      1.008         13        640: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100     0.869G     0.5596     0.5313      1.007         13        640: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.861      0.458       0.52      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100     0.869G     0.4525       0.45     0.9363         13        640: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.852      0.463      0.525      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.109  Python-3.11.9 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060, 8188MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.635      0.783       0.91      0.647\n",
      "                person          3         10      0.616        0.7      0.654      0.325\n",
      "                   dog          1          1      0.517          1      0.995      0.796\n",
      "                 horse          1          2      0.578          1      0.995       0.65\n",
      "              elephant          1          2       0.55          1      0.828      0.323\n",
      "              umbrella          1          1      0.552          1      0.995      0.895\n",
      "          potted plant          1          1          1          0      0.995      0.895\n",
      "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Source\\iot-dataanalysis-2025\\runs\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# coco8.yaml - YOLO 훈련에 사용할 데이터셋 정의파일\n",
    "train_results = model.train(\n",
    "    data='./coco8.yaml', \n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1ca63",
   "metadata": {},
   "source": [
    "#### 이미지 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b6feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Source\\iot-dataanalysis-2025\\day08\\0000001.jpg: 480x640 1 cat, 49.3ms\n",
      "Speed: 3.2ms preprocess, 49.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model('./0000001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c248098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maptplotlib 모듈 로드\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b94dbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측결과 이미지 저장\n",
    "img = result[0].plot()\n",
    "img_pil = Image.fromarray(img[..., ::-1])\n",
    "img_pil.save('./predict_result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643ee27",
   "metadata": {},
   "source": [
    "### OpenCV\n",
    "- Opensource Computer Vision 약자. 실시간 컴퓨터 비전(시각처리)을 목적으로 프로그래밍 라이브러리\n",
    "- 인텔에서 2000년에 C, C++ 사용하기 위해서 개발\n",
    "- 파이썬에서 사용할 수 있게 래핑\n",
    "\n",
    "```shell\n",
    "> pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "090611de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# OpenCV 설치\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fcbe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.11.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4f1ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 640, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('./predict_result.jpg')\n",
    "img2.shape   # (464, 640, 3) -> (height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03fd99b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윈도우 창 오픈\n",
    "cv2.imshow('predict result', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3981ae",
   "metadata": {},
   "source": [
    "#### YOLO 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a43d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 1 bottle, 1 cup, 1 bowl, 1 tv, 1 mouse, 1 book, 43.9ms\n",
      "Speed: 1.4ms preprocess, 43.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./0000002.jpg')\n",
    "resized_img = cv2.resize(img, (640, 400))\n",
    "\n",
    "result = model(resized_img)\n",
    "plots = result[0].plot()\n",
    "\n",
    "cv2.imshow('predict_result', plots)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c0e6c",
   "metadata": {},
   "source": [
    "#### 동영상 플레이\n",
    "- 라즈베리파이에서 동일하게 사용가능\n",
    "- 라즈베리파이 웹캠 사용추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d06588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 파일 경로\n",
    "video_path = './sample01.mp4'\n",
    "output_path = './sample01_output.mp4'\n",
    "count_path = './sample01_count.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ce0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동영상 플레이\n",
    "cap = cv2.VideoCapture(video_path)  # 0 -> 웹캡이나 카메라 설치된 번호\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    cv2.imshow('Video play', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # q버튼을 누르면\n",
    "        break\n",
    "\n",
    "cap.release()  # 비디오를 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c0abb",
   "metadata": {},
   "source": [
    "#### YOLO 실시간 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90fd6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 모듈 로드\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efabf808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 44.4ms\n",
      "Speed: 1.2ms preprocess, 44.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 1.3ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 0.9ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 9.5ms\n",
      "Speed: 0.9ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.6ms\n",
      "Speed: 1.0ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.8ms\n",
      "Speed: 1.5ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 11.7ms\n",
      "Speed: 0.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 8.7ms\n",
      "Speed: 0.9ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 microwave, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 1.0ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.2ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.8ms\n",
      "Speed: 1.2ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 baseball glove, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.2ms\n",
      "Speed: 1.0ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 0.9ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.0ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 10.7ms\n",
      "Speed: 0.9ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.9ms\n",
      "Speed: 1.3ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.5ms\n",
      "Speed: 1.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 9.1ms\n",
      "Speed: 0.9ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.3ms\n",
      "Speed: 0.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.7ms\n",
      "Speed: 1.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.6ms\n",
      "Speed: 0.9ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 9.7ms\n",
      "Speed: 0.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.7ms\n",
      "Speed: 1.0ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 9.2ms\n",
      "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 2.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.2ms\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.7ms\n",
      "Speed: 1.2ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.3ms\n",
      "Speed: 1.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 10.2ms\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 0.9ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 13.7ms\n",
      "Speed: 0.9ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.1ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.4ms\n",
      "Speed: 0.9ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.8ms\n",
      "Speed: 0.9ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.9ms\n",
      "Speed: 0.9ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 0.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.2ms\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.2ms\n",
      "Speed: 0.9ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 12.6ms\n",
      "Speed: 1.0ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 0.9ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 2.3ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 1.0ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.9ms\n",
      "Speed: 0.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 1.1ms preprocess, 10.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.7ms\n",
      "Speed: 1.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.7ms\n",
      "Speed: 1.4ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.8ms\n",
      "Speed: 1.0ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.2ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.8ms\n",
      "Speed: 2.1ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.8ms\n",
      "Speed: 1.2ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 1.7ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.6ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.1ms preprocess, 11.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.6ms\n",
      "Speed: 1.0ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.9ms\n",
      "Speed: 1.7ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.3ms\n",
      "Speed: 1.0ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 1.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 1.6ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.7ms\n",
      "Speed: 1.1ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.2ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 1.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.1ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.2ms\n",
      "Speed: 1.6ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.8ms\n",
      "Speed: 1.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 1.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.2ms preprocess, 7.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.3ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.3ms\n",
      "Speed: 1.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.7ms\n",
      "Speed: 1.0ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.6ms\n",
      "Speed: 0.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.4ms\n",
      "Speed: 1.1ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.6ms\n",
      "Speed: 1.0ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.3ms\n",
      "Speed: 1.2ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.2ms\n",
      "Speed: 1.1ms preprocess, 10.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.2ms\n",
      "Speed: 1.3ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 14.0ms\n",
      "Speed: 1.7ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.0ms\n",
      "Speed: 1.2ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.1ms\n",
      "Speed: 0.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.7ms\n",
      "Speed: 2.1ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.3ms\n",
      "Speed: 0.9ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.1ms\n",
      "Speed: 0.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.1ms\n",
      "Speed: 0.9ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 8.9ms\n",
      "Speed: 0.9ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 baseball bat, 6.5ms\n",
      "Speed: 0.9ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.4ms\n",
      "Speed: 1.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 0.9ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.8ms\n",
      "Speed: 0.9ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.1ms\n",
      "Speed: 1.0ms preprocess, 11.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.6ms\n",
      "Speed: 0.9ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.9ms\n",
      "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 1.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.7ms\n",
      "Speed: 1.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.9ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 1.0ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path) \n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   # 동영상 FPS(Frame Per Second)\n",
    "frame_time = 1.0 /fps  # 초단위로 변환\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))      # 1280\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    # 720\n",
    "\n",
    "# VideoWriter 객체 생성(동영상 화면에 그림, 글자를 그리기 위한 객체)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time() # 시작시간 \n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # 객체 탐지\n",
    "    results = model(frame)\n",
    "    # 탐지 결과 그리기\n",
    "    for result in results:\n",
    "        detect_frame = result.plot()\n",
    "    # 결과프레임을 파일로 저장\n",
    "    out.write(detect_frame)\n",
    "    # 결과 표시\n",
    "    cv2.imshow('YOLO Object Detection', detect_frame)\n",
    "    cv2.imshow('Video play', frame)\n",
    "\n",
    "    # 프레임간 실제 지연시간 계산\n",
    "    elapsed_time = time.time() - start_time\n",
    "    delay = max(int((frame_time  - elapsed_time) * 1000), 1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # q버튼을 누르면\n",
    "        break\n",
    "\n",
    "cap.release()  # 비디오를 해제\n",
    "out.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c170353",
   "metadata": {},
   "source": [
    "#### Car Counting\n",
    "- 지정된 라인 아래로 내려오는 자동차 개수 카운팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1cbf10",
   "metadata": {},
   "source": [
    "- shapely 설치\n",
    "\n",
    "```shell\n",
    "> pip install shapely==2.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dd00729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely==2.0.1\n",
      "  Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from shapely==2.0.1) (1.26.4)\n",
      "Downloading shapely-2.0.1-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.4 MB 640.0 kB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/1.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.4 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.1/1.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# shapely 설치\n",
    "!pip install shapely==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "324cee44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lap\n",
      "  Downloading lap-0.5.12-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\source\\iot-dataanalysis-2025\\mlvenv\\lib\\site-packages (from lap) (1.26.4)\n",
      "Downloading lap-0.5.12-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# lap 설치\n",
    "!pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9279a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22584600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': [(20, 400), (1080, 400)], 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': None, 'records': 5, 'model': 'yolo11n.pt', 'classes_names': {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}, 'show': True}\n",
      "\n",
      "0: 384x640 1 train, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.7ms\n",
      "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.7ms\n",
      "Speed: 1.0ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.4ms\n",
      "Speed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.9ms\n",
      "Speed: 1.2ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 9.9ms\n",
      "Speed: 1.0ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.9ms\n",
      "Speed: 1.1ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.2ms\n",
      "Speed: 1.9ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=1, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 1, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.3ms\n",
      "Speed: 2.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.7ms\n",
      "Speed: 1.7ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 8.0ms\n",
      "Speed: 1.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 10.8ms\n",
      "Speed: 1.1ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=2, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 2, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 8.9ms\n",
      "Speed: 1.0ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.8ms\n",
      "Speed: 1.0ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.3ms\n",
      "Speed: 1.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.0ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.5ms\n",
      "Speed: 1.1ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 10.9ms\n",
      "Speed: 1.7ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=3, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 3, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 9.3ms\n",
      "Speed: 4.1ms preprocess, 9.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 10.0ms\n",
      "Speed: 1.3ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=4, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 4, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 14.0ms\n",
      "Speed: 1.4ms preprocess, 14.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 6.7ms\n",
      "Speed: 1.3ms preprocess, 6.7ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 10.2ms\n",
      "Speed: 1.5ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 4 cars, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.5ms\n",
      "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 2.1ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 truck, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=4)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.9ms\n",
      "Speed: 1.3ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.6ms\n",
      "Speed: 1.1ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.8ms\n",
      "Speed: 2.0ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.9ms\n",
      "Speed: 1.1ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 10.3ms\n",
      "Speed: 1.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=2)\n",
      "\n",
      "0: 384x640 1 train, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 1 train, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=1)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.4ms\n",
      "Speed: 1.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 8.8ms\n",
      "Speed: 1.9ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=3)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 10.7ms\n",
      "Speed: 1.1ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 6.8ms\n",
      "Speed: 1.2ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.0ms\n",
      "Speed: 1.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 7.5ms\n",
      "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 6.6ms\n",
      "Speed: 1.2ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 6 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.1ms preprocess, 10.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.3ms\n",
      "Speed: 1.8ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 13.9ms\n",
      "Speed: 1.5ms preprocess, 13.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 15.3ms\n",
      "Speed: 1.7ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 9.3ms\n",
      "Speed: 4.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 13.7ms\n",
      "Speed: 1.9ms preprocess, 13.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 14.2ms\n",
      "Speed: 1.3ms preprocess, 14.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.7ms\n",
      "Speed: 1.3ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 8.0ms\n",
      "Speed: 1.3ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 9.4ms\n",
      "Speed: 1.1ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 8.8ms\n",
      "Speed: 1.1ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.9ms\n",
      "Speed: 1.0ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=5, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 5, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 10 cars, 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=10)\n",
      "\n",
      "0: 384x640 10 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=10)\n",
      "\n",
      "0: 384x640 9 cars, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 9 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=6, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 6, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 7.4ms\n",
      "Speed: 1.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.8ms\n",
      "Speed: 1.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=7, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 7, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 1 train, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.7ms\n",
      "Speed: 1.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 1 cell phone, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 9.7ms\n",
      "Speed: 1.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 5 cars, 1 suitcase, 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.2ms\n",
      "Speed: 1.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 9.4ms\n",
      "Speed: 1.2ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 7 cars, 8.7ms\n",
      "Speed: 2.8ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.2ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 9.3ms\n",
      "Speed: 1.1ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 8 cars, 10.7ms\n",
      "Speed: 1.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 7.3ms\n",
      "Speed: 1.1ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 8 cars, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=8, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 8, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=8)\n",
      "\n",
      "0: 384x640 7 cars, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 8.3ms\n",
      "Speed: 1.1ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 7.2ms\n",
      "Speed: 1.1ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 8.7ms\n",
      "Speed: 1.1ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 7 cars, 10.4ms\n",
      "Speed: 1.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 9 cars, 8.9ms\n",
      "Speed: 1.1ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 8 cars, 1 train, 11.0ms\n",
      "Speed: 4.1ms preprocess, 11.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=9)\n",
      "\n",
      "0: 384x640 7 cars, 8.1ms\n",
      "Speed: 3.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=7)\n",
      "\n",
      "0: 384x640 6 cars, 13.7ms\n",
      "Speed: 1.6ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.2ms\n",
      "Speed: 1.3ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.3ms\n",
      "Speed: 3.3ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.4ms\n",
      "Speed: 1.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 4.1ms preprocess, 9.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.8ms\n",
      "Speed: 4.5ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=9, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 9, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 11.6ms\n",
      "Speed: 1.0ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 9.6ms\n",
      "Speed: 1.1ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.3ms\n",
      "Speed: 1.2ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 10.7ms\n",
      "Speed: 1.0ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=10, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 10, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 8.5ms\n",
      "Speed: 1.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 5 cars, 1 train, 9.6ms\n",
      "Speed: 1.2ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 5 cars, 7.5ms\n",
      "Speed: 1.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 4 cars, 1 train, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=5)\n",
      "\n",
      "0: 384x640 6 cars, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 9.0ms\n",
      "Speed: 1.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.9ms\n",
      "Speed: 1.2ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n",
      "\n",
      "0: 384x640 6 cars, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      " Results: SolutionResults(in_count=11, classwise_count={'train': {'IN': 0, 'OUT': 0}, 'car': {'IN': 11, 'OUT': 0}, 'truck': {'IN': 0, 'OUT': 0}, 'cell phone': {'IN': 0, 'OUT': 0}, 'suitcase': {'IN': 0, 'OUT': 0}}, total_tracks=6)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics.solutions import ObjectCounter\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), 'Error reading video file'  # 파일 열리지 않으면 경고처리\n",
    "\n",
    "region_points = [(20, 400), (1080, 400)]   # 라인수\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)   # 동영상 FPS(Frame Per Second)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))      # 1280\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))    # 720\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(count_path, fourcc, fps, (width, height))\n",
    "# 물체 인식 핵심 객체\n",
    "counter = ObjectCounter(\n",
    "    show=True,                  # 처리중 화면에 디스플레이\n",
    "    region=region_points,       # 라인위치\n",
    "    model='yolo11n.pt',         # YOLO 모델\n",
    "    # classes=[0, 2],\n",
    "    # tracker='botsort.yaml', \n",
    ")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    results = counter(frame)\n",
    "    out.write(results.plot_im)  # 여기 차이    \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
